{"cells":[{"cell_type":"code","source":["import findspark\n","from pyspark.ml.feature import VectorAssembler\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n"],"metadata":{"id":"lwTGwggCSvtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"modelos\")\\\n","            .config(\"spark.driver.extraClassPath\", \"postgresql-42.2.14.jar\") \\\n","            .config(\"spark.executor.extraClassPath\", \"postgresql-42.2.14.jar\") \\\n","            .getOrCreate()\n","sc =  spark.sparkContext"],"metadata":{"id":"q4HbCpAnQQR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["posgres_df = spark \\\n","    .read \\\n","    .format(\"jdbc\") \\\n","    .option(\"url\", \"jdbc:postgresql://host.docker.internal:5433/postgres\") \\\n","    .option(\"user\", \"postgres\") \\\n","    .option(\"password\", \"testPassword\") \\\n","    .option(\"dbtable\", \"proyecto\") \\\n","    .load()\n","posgres_df.show()"],"metadata":{"id":"YDTmkeOqHHDA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lista de columnas X1, X2, ..., X16\n","feature_columns = [\"X{}\".format(i) for i in range(1, 17)]\n","\n","# 1. Utilizar VectorAssembler para ensamblar las características en una sola columna \"features\"\n","assembler = VectorAssembler(inputCols=feature_columns, outputCol='scaled_features')\n","scaled_df = assembler.transform(posgres_df)\n","\n","# 2. Seleccionar solo las columnas \"features\" y \"Y\" para el DataFrame final\n","scaled_df = scaled_df.select(['scaled_features', 'Y'])\n","\n","# Mostrar el DataFrame resultante\n","scaled_df.show(truncate=False)\n"],"metadata":{"id":"_FozTeZOQGBS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n","\n","# Lista de columnas X1, X2, ..., X16\n","feature_columns = [\"X{}\".format(i) for i in range(1, 17)]\n","\n","# 1. Utilizar VectorAssembler para ensamblar las características en una sola columna \"features\"\n","assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n","scaled_df = assembler.transform(posgres_df)\n","\n","# 2. Seleccionar solo las columnas \"features\" y \"Y\" para el DataFrame final\n","scaled_df = scaled_df.select(['features', 'Y'])\n","\n","# Mostrar el DataFrame resultante\n","scaled_df.show(truncate=False)\n"],"metadata":{"id":"wYy6_gs1Pv9i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml import Pipeline\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","train_data, test_data = scaled_df.randomSplit([0.8, 0.2], seed=42)\n","\n","# Crear un modelo de regresión logística\n","lr = LogisticRegression(featuresCol='scaled_features', labelCol='Y', maxIter=10)\n","\n","# Crear un pipeline con el modelo\n","pipeline_lr = Pipeline(stages=[lr])\n","\n","# Ajustar el modelo al conjunto de entrenamiento\n","model_lr = pipeline_lr.fit(train_data)\n","\n","# Realizar predicciones en el conjunto de prueba\n","predictions_lr = model_lr.transform(test_data)\n","\n","# Evaluar el rendimiento del modelo\n","evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Y')\n","area_under_curve = evaluator.evaluate(predictions_lr, {evaluator.metricName: 'areaUnderROC'})\n","\n","# Mostrar el rendimiento del modelo\n","print(f\"Área bajo la curva ROC: {area_under_curve}\")\n"],"metadata":{"id":"yK15Q1f0QHt6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml import Pipeline\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","train_data, test_data = scaled_df.randomSplit([0.8, 0.2], seed=42)\n","\n","# Crear un modelo Random Forest\n","rf = RandomForestClassifier(featuresCol='scaled_features', labelCol='Y', numTrees=100, maxDepth=5)\n","\n","# Crear un pipeline con el modelo\n","pipeline_rf = Pipeline(stages=[rf])\n","\n","# Ajustar el modelo al conjunto de entrenamiento\n","model_rf = pipeline_rf.fit(train_data)\n","\n","# Realizar predicciones en el conjunto de prueba\n","predictions_rf = model_rf.transform(test_data)\n","\n","# Evaluar el rendimiento del modelo\n","evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Y')\n","area_under_curve = evaluator.evaluate(predictions_rf, {evaluator.metricName: 'areaUnderROC'})\n","\n","# Mostrar el rendimiento del modelo\n","print(f\"Área bajo la curva ROC: {area_under_curve}\")\n"],"metadata":{"id":"al7G3vdTTA8R"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3HMKLyowIFvySwQ7FLQG8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}